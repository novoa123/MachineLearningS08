{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🧪 Actividad Evaluada: Árboles de Decisión en el Dataset Titanic\n",
        "\n",
        "📚 **Curso:** Machine Learning\n",
        "\n",
        "## 📝 Instrucciones\n",
        "- Este notebook debe ser completado individualmente y subido a la plataforma del curso.\n",
        "- Responde todas las celdas marcadas como código y asegúrate de que el notebook se ejecute sin errores.\n",
        "- Puedes usar material del curso y documentación oficial de Python y Scikit-learn.\n",
        "\n",
        "## 📄 Descripción del Dataset\n",
        "El dataset **Titanic** contiene información sobre los pasajeros del famoso barco Titanic que naufragó en 1912. El objetivo es predecir si un pasajero sobrevivió o no (`Survived` = 1 si sobrevivió, 0 si no), a partir de variables como edad, clase, sexo, y punto de embarque.\n",
        "\n",
        "Este conjunto de datos es ampliamente utilizado en aprendizaje automático como un primer ejemplo de clasificación supervisada.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🌊 Actividad Evaluada: Árboles de Decisión con el Dataset Titanic\n",
        "\n",
        "En esta actividad aplicarás un modelo de árboles de decisión sobre el dataset Titanic.\n",
        "\n",
        "### 🎯 Objetivos:\n",
        "- Cargar y explorar el dataset\n",
        "- Preprocesar las variables categóricas con One Hot Encoding\n",
        "- Entrenar un árbol de decisión\n",
        "- Visualizar el árbol\n",
        "- Evaluar el desempeño del modelo\n",
        "\n",
        "🕐 Tiempo estimado: 60 a 90 minutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📥 Cargar el dataset desde la URL de Kaggle (alternativamente cargar localmente)\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔍 1. Exploración inicial del dataset\n",
        "\n",
        "Antes de comenzar a entrenar modelos de Machine Learning, es fundamental **comprender la estructura y el contenido del conjunto de datos**. En esta sección, deberás realizar una exploración básica del dataset Titanic para identificar:\n",
        "\n",
        "- Las columnas disponibles y sus tipos de datos (`.info()`)\n",
        "- Las estadísticas descriptivas de las variables numéricas (`.describe()`)\n",
        "- La existencia de valores faltantes (`.isnull().sum()`)\n",
        "\n",
        "Estas acciones te permitirán decidir qué pasos de limpieza y preprocesamiento son necesarios. **Recuerda comentar brevemente tus observaciones** al final de esta sección, por ejemplo: si hay columnas con muchos datos faltantes, si hay outliers o si ciertas variables parecen poco informativas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧹 2. Preprocesamiento\n",
        "\n",
        "Antes de entrenar un modelo de Machine Learning, es necesario **preparar adecuadamente los datos**. Este proceso se conoce como *preprocesamiento* y consiste en dejar el conjunto de datos en un formato que los algoritmos puedan utilizar de manera efectiva.\n",
        "\n",
        "### Pasos a seguir:\n",
        "\n",
        "1. **Eliminar columnas innecesarias**: Algunas columnas como `PassengerId`, `Name`, `Ticket` o `Cabin` no aportan información útil al modelo o contienen datos difíciles de procesar automáticamente (como texto libre o demasiados valores únicos).\n",
        "\n",
        "2. **Manejo de valores faltantes**:\n",
        "   - La columna `Age` tiene valores faltantes que puedes reemplazar por la **mediana**, ya que es menos sensible a valores extremos.\n",
        "   - La columna `Embarked` tiene pocos valores faltantes, así que puedes usar la **moda** (valor más frecuente) para completarlos.\n",
        "\n",
        "3. **Codificación de variables categóricas**:\n",
        "   - Los algoritmos no pueden trabajar directamente con texto. Por eso, aplicamos **One Hot Encoding** a las variables categóricas como `Sex` y `Embarked`, transformándolas en columnas binarias (0 y 1).\n",
        "   - Usar `drop_first=True` evita multicolinealidad y reduce la cantidad de columnas.\n",
        "\n",
        "> ⚠️ **Importante:** El preprocesamiento tiene un gran impacto en la calidad del modelo. Un paso mal hecho puede afectar seriamente el desempeño del algoritmo.\n",
        "\n",
        "Al finalizar esta etapa, deberías tener un dataset **limpio, sin valores nulos y completamente numérico**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧠 3. Entrenamiento del modelo de Árbol de Decisión\n",
        "\n",
        "En esta etapa, construiremos un modelo predictivo utilizando un **Árbol de Decisión**, una técnica de clasificación que divide los datos en ramas sucesivas para tomar decisiones basadas en las características del conjunto de datos.\n",
        "\n",
        "### Pasos a seguir:\n",
        "\n",
        "1. **Separar las variables predictoras (X) y la variable objetivo (y)**.  \n",
        "   En este caso, `Survived` será nuestra variable objetivo, y el resto de las columnas las usaremos como predictores.\n",
        "\n",
        "2. **Dividir los datos en conjuntos de entrenamiento y prueba**.  \n",
        "   Esto se hace para evaluar el modelo con datos que no ha visto antes. Usa `train_test_split` para crear una división, por ejemplo 70% entrenamiento y 30% prueba.\n",
        "\n",
        "3. **Crear y entrenar el modelo con `DecisionTreeClassifier`**.  \n",
        "   Puedes usar el parámetro `max_depth` para limitar la profundidad del árbol y evitar sobreajuste.\n",
        "\n",
        "Cuando termines esta sección, tu modelo estará entrenado y listo para ser evaluado y visualizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🌳 4. Visualización del árbol\n",
        "\n",
        "Una de las grandes ventajas de los árboles de decisión es que su estructura se puede visualizar de forma intuitiva, lo que facilita la **interpretación del modelo**.\n",
        "\n",
        "En esta sección usaremos la función `plot_tree()` de `sklearn` para graficar el árbol entrenado. En el gráfico:\n",
        "\n",
        "- Cada **nodo interno** representa una condición de decisión sobre alguna variable.\n",
        "- Cada **rama** muestra el resultado de esa decisión (verdadero o falso).\n",
        "- Cada **nodo terminal** (o hoja) muestra la clase predicha y cuántas muestras llegaron a ese punto.\n",
        "\n",
        "### Sugerencia:\n",
        "Puedes ajustar los parámetros de `plot_tree()` como `feature_names`, `class_names` y `filled=True` para mejorar la legibilidad del árbol. Asegúrate de usar `plt.figure(figsize=(ancho, alto))` para que la visualización no se corte.\n",
        "\n",
        "**Objetivo:** Entender cómo el modelo está tomando decisiones, qué variables usa y con qué prioridad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📈 5. Evaluación del modelo\n",
        "\n",
        "Una vez entrenado el modelo, es fundamental **evaluar su desempeño** para entender qué tan bien está funcionando. En esta sección usaremos datos de prueba (no vistos por el modelo durante el entrenamiento) para calcular métricas que nos ayuden a juzgar la calidad de las predicciones.\n",
        "\n",
        "### Métricas que utilizaremos:\n",
        "\n",
        "- **Matriz de confusión (`confusion_matrix`)**: muestra la cantidad de verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos. Es útil para entender errores específicos del modelo.\n",
        "- **Reporte de clasificación (`classification_report`)**: incluye precisión (*precision*), exhaustividad (*recall*), y la métrica F1 para cada clase.\n",
        "- **Exactitud (`accuracy_score`)**: indica qué porcentaje total de predicciones fue correcto.\n",
        "\n",
        "Estas métricas te permitirán **identificar si el modelo está desbalanceado**, si tiende a predecir más una clase que otra, y si necesita ajustes en parámetros o preprocesamiento.\n",
        "\n",
        "> 💡 Recuerda: un modelo con buena precisión pero bajo *recall* puede ser problemático si nos interesa no dejar pasar casos positivos (como sobrevivientes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 🤔 Preguntas de Reflexión\n",
        "\n",
        "Responde brevemente las siguientes preguntas al final de tu actividad. Puedes escribir tus respuestas directamente bajo cada pregunta:\n",
        "\n",
        "1. ¿Qué variables crees que fueron más importantes para predecir la supervivencia? ¿Por qué?\n",
        "\n",
        "2. ¿Qué limitaciones puede tener un árbol de decisión si no se controla su profundidad?\n",
        "\n",
        "3. ¿Qué diferencias habría si usáramos codificación ordinal en lugar de One Hot Encoding?\n",
        "\n",
        "4. ¿Qué cambiarías en el preprocesamiento o configuración del modelo para mejorar los resultados?\n",
        "\n",
        "5. ¿Crees que este modelo se puede usar directamente en un entorno real? ¿Qué consideraciones éticas o técnicas deberías tener?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. ¿Qué variables crees que fueron más importantes para predecir la supervivencia? ¿Por qué?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu respuesta aquí...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. ¿Qué limitaciones puede tener un árbol de decisión si no se controla su profundidad?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu respuesta aquí...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. ¿Qué diferencias habría si usáramos codificación ordinal en lugar de One Hot Encoding?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu respuesta aquí...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. ¿Qué cambiarías en el preprocesamiento o configuración del modelo para mejorar los resultados?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu respuesta aquí...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**5. ¿Crees que este modelo se puede usar directamente en un entorno real? ¿Qué consideraciones éticas o técnicas deberías tener?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu respuesta aquí...\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
